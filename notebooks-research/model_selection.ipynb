{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7efb20e",
   "metadata": {},
   "source": [
    "# Model Selection for Smart Peak Splits\n",
    "\n",
    "This notebook's objective is to select the model that will perform the desired predictions with the highest accuracy, once chosen, the model will be saved for the main pipeline at `orchestrator.py`\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "### Training Phase\n",
    "1. **Data Collection**: GPX files are placed in `data/raw/` folder\n",
    "2. **Feature Extraction**: Run `orchestrator.py` to parse GPX files and extract features (splits with distance, elevation, HR, pace, time)\n",
    "3. **Model Training**: Train models on processed files from `data/processed/`\n",
    "4. **Model Selection**: Evaluate and select the best performing model\n",
    "5. **Save Model**: Save the selected model for inference\n",
    "\n",
    "### Prediction Phase (After Training)\n",
    "1. **Input**: New GPX file from user\n",
    "2. **Parse GPX**: Extract splits data (distance, elevation, HR if available)\n",
    "3. **Model Inference**: Predict for each split:\n",
    "   - Time (seconds)\n",
    "   - Average Pace (min/km)\n",
    "   - Average HR (bpm)\n",
    "4. **Output**: CSV with predicted splits performance\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before proceeding, ensure to run `orchestrator.py` and that GPX files are available in the `data/raw/` folder. You will have processed files in `data/processed/` after running the orchestrator. The processed files are the ones that will be used for training and validating the model.\n",
    "\n",
    "Please check the processed file sample at `data/samples/activity_20738496042_splits_sample.csv`\n",
    "\n",
    "**Note**: There will be a sampling with 5 GPX files, those are supposed to be yours :)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
